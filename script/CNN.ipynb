{"cells":[{"cell_type":"markdown","source":["## **SPECIFIC FOR GOOGLE COLAB**"],"metadata":{"id":"Yh5tRM2Zk7qv"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o1Otm8DNiPTQ","executionInfo":{"status":"ok","timestamp":1639398662894,"user_tz":-60,"elapsed":619,"user":{"displayName":"Etienne BRUNO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15569840842399086043"}},"outputId":"f9fa618c-6d21-4fe0-babe-e5c657f402c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model name:          Intel(R) Xeon(R) CPU @ 2.20GHz\n","Core(s) per socket:  1\n","              total        used        free      shared  buff/cache   available\n","Mem:            12G        627M        9.7G        1.2M        2.3G         11G\n","Swap:            0B          0B          0B\n","Thread(s) per core:  2\n"]}],"source":["!lscpu |grep 'Model name'\n","!lscpu |grep 'Core(s) per socket:'\n","!free -h\n","!lscpu |grep 'Thread(s) per core'"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-x_fynf8iPTT","executionInfo":{"status":"ok","timestamp":1639404343299,"user_tz":-60,"elapsed":26653,"user":{"displayName":"sami ferchiou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02970809549726737451"}},"outputId":"c3c91ce3-6ba5-4466-e140-8285a1fe0121"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/ml_project_2_drive/ml_project_2\n","data  helper_functions.py  project2_description.pdf  README.md\tscript\n"]}],"source":["# Mount Google Drive and load project 2\n","# WARNING, we have to add the shared drive of Sami on our home directory (by creating an alias)\n","from google.colab import drive\n","drive.mount('/content/drive')\n","#Move to the shared directory\n","%cd /content/drive/MyDrive/ml_project_2_drive/ml_project_2/\n","# list all files\n","! ls\n","\n","# Read helpers python file\n","!cp /content/drive/MyDrive/ml_project_2_drive/ml_project_2/script/helper_functions.py .\n","\n","# A good help can be found here:\n","#https://medium.com/analytics-vidhya/how-to-use-google-colab-with-github-via-google-drive-68efb23a42d"]},{"cell_type":"code","source":["!git status\n","#test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Aj7AC6YMHTcg","executionInfo":{"status":"ok","timestamp":1639404499986,"user_tz":-60,"elapsed":978,"user":{"displayName":"sami ferchiou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02970809549726737451"}},"outputId":"8c4bfc03-0279-4fbf-981b-bc142243da50"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes to be committed:\n","  (use \"git reset HEAD <file>...\" to unstage)\n","\n","\t\u001b[32mmodified:   script/CNN.ipynb\u001b[m\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git checkout -- <file>...\" to discard changes in working directory)\n","\n","\t\u001b[31mmodified:   script/CNN.ipynb\u001b[m\n","\n"]}]},{"cell_type":"code","source":["!git log --oneline\n","#!git config --global user.email \"etienne.bruno@epfl.ch\"\n","#!git config --global user.name \"Etienne BRUNO\""],"metadata":{"id":"6Z-rSX7Cj22D","executionInfo":{"status":"ok","timestamp":1639404490600,"user_tz":-60,"elapsed":520,"user":{"displayName":"sami ferchiou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02970809549726737451"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["!git config --global user.email \"sami.ferchiou@epfl.ch\"\n","!git config --global user.name \"samiferchiou\""],"metadata":{"id":"difaWbxzICh2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git pull"],"metadata":{"id":"GEliIqBbxnac","executionInfo":{"status":"ok","timestamp":1639398681876,"user_tz":-60,"elapsed":1010,"user":{"displayName":"Etienne BRUNO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15569840842399086043"}},"outputId":"c46c5a6b-a85b-4193-a1de-1a012ea2fbda","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["remote: Enumerating objects: 12, done.\u001b[K\n","remote: Counting objects:   8% (1/12)\u001b[K\rremote: Counting objects:  16% (2/12)\u001b[K\rremote: Counting objects:  25% (3/12)\u001b[K\rremote: Counting objects:  33% (4/12)\u001b[K\rremote: Counting objects:  41% (5/12)\u001b[K\rremote: Counting objects:  50% (6/12)\u001b[K\rremote: Counting objects:  58% (7/12)\u001b[K\rremote: Counting objects:  66% (8/12)\u001b[K\rremote: Counting objects:  75% (9/12)\u001b[K\rremote: Counting objects:  83% (10/12)\u001b[K\rremote: Counting objects:  91% (11/12)\u001b[K\rremote: Counting objects: 100% (12/12)\u001b[K\rremote: Counting objects: 100% (12/12), done.\u001b[K\n","remote: Compressing objects:  25% (1/4)\u001b[K\rremote: Compressing objects:  50% (2/4)\u001b[K\rremote: Compressing objects:  75% (3/4)\u001b[K\rremote: Compressing objects: 100% (4/4)\u001b[K\rremote: Compressing objects: 100% (4/4), done.\u001b[K\n","remote: Total 8 (delta 4), reused 8 (delta 4), pack-reused 0\u001b[K\n","Unpacking objects:  12% (1/8)   \rUnpacking objects:  25% (2/8)   \rUnpacking objects:  37% (3/8)   \rUnpacking objects:  50% (4/8)   \rUnpacking objects:  62% (5/8)   \rUnpacking objects:  75% (6/8)   \rUnpacking objects:  87% (7/8)   \rUnpacking objects: 100% (8/8)   \rUnpacking objects: 100% (8/8), done.\n","From https://github.com/etiennebruno/cs433_project_2\n","   88d7c85..d9eefed  main       -> origin/main\n","Updating 88d7c85..d9eefed\n","Fast-forward\n"," script/mask_to_submission.py | 46 \u001b[32m+++++++++++++++++++++++++++++++++++++\u001b[m\n"," script/submission_to_mask.py | 54 \u001b[32m++++++++++++++++++++++++++++++++++++++++++++\u001b[m\n"," 2 files changed, 100 insertions(+)\n"," create mode 100644 script/mask_to_submission.py\n"," create mode 100644 script/submission_to_mask.py\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NTEU2fmciPTT","executionInfo":{"status":"ok","timestamp":1639404450627,"user_tz":-60,"elapsed":16330,"user":{"displayName":"sami ferchiou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02970809549726737451"}},"outputId":"83a0edb2-05e4-4c7a-c4f3-53548d402900"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","*** Please tell me who you are.\n","\n","Run\n","\n","  git config --global user.email \"you@example.com\"\n","  git config --global user.name \"Your Name\"\n","\n","to set your account's default identity.\n","Omit --global to set the identity only in this repository.\n","\n","fatal: unable to auto-detect email address (got 'root@343662bfd686.(none)')\n","Everything up-to-date\n"]}],"source":["!git add .\n","!git commit -m \"update from google colab\"\n","!git push"]},{"cell_type":"markdown","source":["## **MACHINE LEARNING MODEL**"],"metadata":{"id":"fQ95PpoTlQtU"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"PDdOg0apiPTT"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.transforms as T\n","import torchvision\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os,sys\n","from PIL import Image\n","from pathlib import Path\n","from tqdm import tqdm\n","import time\n","from torch.optim.lr_scheduler import ExponentialLR\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score\n","\n","from helper_functions import *\n","\n","# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","use_cuda = torch.cuda.is_available()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bqg8mn2fiPTU"},"outputs":[],"source":["NBR_EPOCHS = 2\n","BATCH_SIZE = 10\n","LEARNING_RATE =1e-3\n","WEIGHT_DECAY=0.01\n","DIM = 1\n","GAMMA = 0.9"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tUus_IThiPTU"},"outputs":[],"source":["def load_train_dataset():\n","    # Loaded a set of images\n","    root_dir = \"../data/training/\"\n","    #root_dir = \"/content/drive/MyDrive/ml_project_2_drive/ml_project_2/data/training/\"\n","    image_dir = root_dir + \"images/\"\n","    gt_dir = root_dir + \"groundtruth/\"\n","    files = os.listdir(image_dir)\n","    n = len(files)\n","    to_tensor = T.ToTensor()\n","    imgs = [to_tensor(Image.open(image_dir + files[i])) for i in range(n)]\n","    gt_imgs = [to_tensor(Image.open(gt_dir + files[i])).type(torch.LongTensor) for i in range(n)]\n","    return (imgs, gt_imgs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mcXIHBOliPTV","outputId":"3f4fbb8f-feb6-4f2b-d1d5-8c1a26a24742"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 1min 20s, sys: 1min 17s, total: 2min 37s\n","Wall time: 3min 32s\n"]}],"source":["%%time\n","from torch.utils.data import Dataset, DataLoader\n","\n","# load initial images\n","imgs_init, gt_imgs_init = load_train_dataset()\n","# proceed to data augmnetation on both train images and ground truth images\n","all_imgs = compose_all_functions_for_data(imgs_init)\n","all_gt_imgs = compose_all_functions_for_data(gt_imgs_init)\n","\n","# split data into training and validation sets\n","x_train, x_validation, y_train, y_validation = train_test_split(all_imgs, all_gt_imgs, test_size=0.2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q_CAir3NiPTV","outputId":"2c98b288-cc71-448c-f29d-719b71307dad"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 3.51 ms, sys: 17.5 ms, total: 21 ms\n","Wall time: 67 ms\n"]}],"source":["%%time\n","\n","class trainDataset(Dataset): \n","    def __init__(self, x_train, y_train):\n","        # Data augmentation\n","        self.x_train = x_train\n","        self.y_train = y_train\n","        self.n_samples = len(self.x_train)\n","        \n","    def __getitem__(self, index):\n","        return self.x_train[index], self.y_train[index]\n","\n","    def __len__(self):\n","        return self.n_samples\n","\n","class validateDataset(Dataset): \n","    def __init__(self, x_validation, y_validation):\n","        # Data augmentation\n","        self.x_validation = x_validation\n","        self.y_validation = y_validation\n","        self.n_samples = len(self.x_validation)\n","        \n","    def __getitem__(self, index):\n","        return self.x_validation[index], self.y_validation[index]\n","\n","    def __len__(self):\n","        return self.n_samples\n","\n","# create datasets\n","torch.manual_seed(1)\n","trainset = trainDataset(x_train, y_train)\n","testset = validateDataset(x_validation, y_validation)\n","loaders = {\n","    'train_loader' : torch.utils.data.DataLoader(trainset, batch_size = BATCH_SIZE, shuffle=True),\n","    'test_loader'  : torch.utils.data.DataLoader(testset, batch_size = BATCH_SIZE, shuffle=True),\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"js7xQX21iPTW"},"outputs":[],"source":["#img_temp = trainset[5432][0]\n","#to_PIL = T.ToPILImage()\n","#to_PIL(img_temp)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kL6Y8pLLiPTW"},"outputs":[],"source":["class ConvNet(nn.Module):\n","    def __init__(self):\n","        super(ConvNet, self).__init__()\n","        \n","        # \n","        self.pool_d = nn.MaxPool2d(2, 2)\n","        self.pool_u = nn.Upsample(scale_factor=2)\n","        \n","        # Activation function\n","        self.activ = nn.ReLU()\n","        self.final_activ = nn.Sigmoid()\n","        \n","        # Convolution Downwards\n","        self.conv_1 = nn.Conv2d(3, 64, (3,3), padding=(1, 1))\n","        self.conv_2 = nn.Conv2d(64, 64, (3,3), padding=(1, 1))\n","        \n","        self.conv_3 = nn.Conv2d(64, 128, (3,3), padding=(1, 1))\n","        self.conv_4 = nn.Conv2d(128, 128, (3,3), padding=(1, 1))\n","        \n","        self.conv_5 = nn.Conv2d(128, 256, (3,3), padding=(1, 1))\n","        self.conv_6 = nn.Conv2d(256, 256, (3,3), padding=(1, 1))\n","        \n","        self.conv_7 = nn.Conv2d(256, 512, (3,3), padding=(1, 1))\n","        self.conv_8 = nn.Conv2d(512, 512, (3,3), padding=(1, 1))\n","        \n","        self.conv_9 = nn.Conv2d(512, 1024, (3,3), padding=(1, 1))\n","        self.conv_10 = nn.Conv2d(1024, 1024, (3,3), padding=(1, 1))\n","        \n","        \n","        # Upconvolution\n","        self.upconv_1 = nn.Conv2d(512+1024, 512, (3,3), padding=(1, 1))\n","        self.upconv_2 = nn.Conv2d(512, 512, (3,3), padding=(1, 1))\n","        \n","        self.upconv_3 = nn.Conv2d(256+512, 256, (3,3), padding=(1, 1))\n","        self.upconv_4 = nn.Conv2d(256, 256, (3,3), padding=(1, 1))\n","        \n","        self.upconv_5 = nn.Conv2d(128+256, 128, (3,3), padding=(1, 1))\n","        self.upconv_6 = nn.Conv2d(128, 128, (3,3), padding=(1, 1))\n","        \n","        self.upconv_7 = nn.Conv2d(64+128, 64, (3,3), padding=(1, 1))\n","        self.upconv_8 = nn.Conv2d(64, 64, (3,3), padding=(1, 1))\n","        self.upconv_9 = nn.Conv2d(64, 2, (1,1))\n","\n","\n","    def forward(self, x):\n","        # Convolution with activation and max_pooling\n","        xd_1 = self.activ(self.conv_1(x))\n","        xd_2 = self.activ(self.conv_2(xd_1))\n","    \n","        xd_3 = self.activ(self.conv_3(self.pool_d(xd_2)))\n","        xd_4 = self.activ(self.conv_4(xd_3))\n","        \n","        xd_5 = self.activ(self.conv_5(self.pool_d(xd_4)))\n","        xd_6 = self.activ(self.conv_6(xd_5))\n","        \n","        xd_7 = self.activ(self.conv_7(self.pool_d(xd_6)))\n","        xd_8 = self.activ(self.conv_8(xd_7))\n","        \n","        xd_9 = self.activ(self.conv_9(self.pool_d(xd_8)))\n","        xd_10 = self.pool_u(self.activ(self.conv_10(xd_9)))\n","\n","        # \"Fractionally / Backward strided convolution\" with activation and upsampling\n","        xu_1 = self.activ(self.upconv_1(torch.cat((xd_8, xd_10), dim=DIM)))\n","        xu_2 = self.pool_u(self.activ(self.upconv_2(xu_1)))\n","        \n","        xu_3 = self.activ(self.upconv_3(torch.cat((xd_6, xu_2), dim=DIM)))\n","        xu_4 = self.pool_u(self.activ(self.upconv_4(xu_3)))\n","        \n","        xu_5 = self.activ(self.upconv_5(torch.cat((xd_4, xu_4), dim=DIM)))\n","        xu_6 = self.pool_u(self.activ(self.upconv_6(xu_5)))\n","        \n","        xu_7 = self.activ(self.upconv_7(torch.cat((xd_2, xu_6), dim=DIM)))\n","        xu_8 = self.activ(self.upconv_8(xu_7))\n","        xu_9 = self.final_activ(self.upconv_9(xu_8))\n","    \n","        return xu_9\n","\n","model = ConvNet().to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PzJ60OyIiPTW"},"outputs":[],"source":["def save_ckp(state, is_best, checkpoint_path, best_model_path):\n","    \"\"\"\n","    state:            checkpoint we want to save\n","    is_best:          boolean to indicates if it is the best checkpoint\n","    checkpoint_path:  path to save checkpoint\n","    best_model_path:  path to save best model\n","    \"\"\"\n","    f_path = checkpoint_path\n","    # save checkpoint data to the path given, checkpoint_path\n","    torch.save(state, f_path)\n","    # if it is a best model, min validation loss\n","    if is_best:\n","        best_fpath = best_model_path\n","        # copy that checkpoint file to best path given, best_model_path\n","        shutil.copyfile(f_path, best_fpath)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xJVN7J_uiPTX"},"outputs":[],"source":["def load_ckp(checkpoint_fpath, model, optimizer):\n","    \"\"\"\n","    checkpoint_path: path to save checkpoint\n","    model:           model that we want to load checkpoint parameters into       \n","    optimizer:       optimizer we defined in previous training\n","    \"\"\"\n","    # load check point\n","    checkpoint = torch.load(checkpoint_fpath)\n","    # initialize state_dict from checkpoint to model\n","    model.load_state_dict(checkpoint['state_dict'])\n","    # initialize optimizer from checkpoint to optimizer\n","    optimizer.load_state_dict(checkpoint['optimizer'])\n","    # initialize valid_loss_min from checkpoint to valid_loss_min\n","    valid_loss_min = checkpoint['valid_loss_min']\n","    # initialize the adaptative learning rate\n","    scheduler = checkpoint['scheduler']\n","    # return model, optimizer, epoch value, min validation loss\n","    return model, optimizer, checkpoint['epoch'], valid_loss_min.item(), scheduler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cRXk73khiPTX"},"outputs":[],"source":["def train(start_epochs, n_epochs, valid_loss_min_input, loaders, model, optimizer, scheduler, criterion, use_cuda, checkpoint_path, best_model_path):\n","    \"\"\"\n","    \"\"\"\n","    # initialize tracker for minimum validation loss\n","    valid_loss_min = valid_loss_min_input \n","    \n","    for epoch in range(start_epochs, n_epochs+1):\n","        # initialize variables to monitor training and validation loss\n","        train_loss = 0.0\n","        valid_loss = 0.0\n","        \n","        ###################\n","        # train the model #\n","        ###################\n","        model.train()\n","        train_steps = len(loaders['train_loader'].dataset)\n","        for batch_idx, (data, target) in enumerate(loaders['train_loader']):\n","            # Measure training time of one batch sample\n","            start = time.time()\n","        \n","            # move to GPU\n","            if use_cuda:\n","                data, target = data.cuda(), target.cuda()\n","            \n","            ## find the loss and update the model parameters accordingly\n","            # clear the gradients of all optimized variables\n","            optimizer.zero_grad()\n","            # forward pass: compute predicted outputs by passing inputs to the model\n","            output = model(data)\n","            # calculate the batch loss\n","            print(target.shape)\n","            print(output.shape)\n","            pred_training= torch.reshape(target, (BATCH_SIZE, 400, 400))\n","            loss = criterion(output, pred_training)\n","            # backward pass: compute gradient of the loss with respect to model parameters\n","            loss.backward()\n","            # perform a single optimization step (parameter update)\n","            optimizer.step()\n","            ## record the average training loss, using something like\n","            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n","            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n","            \n","            print(f\"Epoch {epoch},  Batch {batch_idx}/{train_steps} - Duration: {time.time()-start}, Loss:{loss.item():.4f}\")\n","        \n","        ######################    \n","        # validate the model #\n","        ######################\n","        model.eval()\n","        test_steps = len(loaders['test_loader'].dataset)\n","        for batch_idx, (data, target) in enumerate(loaders['test_loader']):\n","            # move to GPU\n","            if use_cuda:\n","                data, target = data.cuda(), target.cuda()\n","           \n","            ## update the average validation loss\n","            # forward pass: compute predicted outputs by passing inputs to the model\n","            output = model(data)\n","            # calculate the batch loss\n","            pred_eval= torch.reshape(target, (BATCH_SIZE, 400, 400))\n","            loss = criterion(output, pred_eval)\n","            # update average validation loss \n","            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n","            \n","            # F1 score computation\n","            prediction_raveled = torch.flatten(torch.argmax(pred_eval, dim=1))\n","            y_validation_raveled = torch.flatten(target)\n","            f1 = f1_score(y_validation_raveled, prediction_raveled)\n","            print(f'{f1 = }')\n","        \n","        # perform a step of the adaptative learning rate\n","        scheduler.step()\n","    \n","        # calculate average losses\n","        train_loss = train_loss/train_steps\n","        valid_loss = valid_loss/test_steps\n","\n","        # print training/validation statistics \n","        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n","            epoch, \n","            train_loss,\n","            valid_loss\n","            ))\n","        \n","        # create checkpoint variable and add important data\n","        checkpoint = {\n","            'epoch': epoch + 1,\n","            'valid_loss_min': valid_loss,\n","            'state_dict': model.state_dict(),\n","            'optimizer': optimizer.state_dict(),\n","            'scheduler': scheduler.get_last_lr(),\n","        }\n","        \n","        # save checkpoint\n","        save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n","        \n","        ## save the model if validation loss has decreased\n","        if valid_loss <= valid_loss_min:\n","            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n","            # save checkpoint as best model\n","            save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n","            valid_loss_min = valid_loss\n","            \n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GmZ_VHjRiPTX","outputId":"9c94d8b6-a1dc-43a4-d427-aa1d681a2ebc"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([10, 1, 400, 400])\n","torch.Size([10, 2, 400, 400])\n","Epoch 1,  Batch 0/7680 - Duration: 177.8477532863617, Loss:0.6941\n","torch.Size([10, 1, 400, 400])\n","torch.Size([10, 2, 400, 400])\n"]}],"source":["#criterion = nn.CrossEntropyLoss()# nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n","#define adaptative learning rate\n","scheduler = ExponentialLR(optimizer, GAMMA)\n","#loss function used in our neural network\n","criterion = nn.CrossEntropyLoss()\n","\n","trained_model = train(1, 3, np.Inf, loaders, model, optimizer, scheduler, criterion, use_cuda,\n","                      \"../checkpoint/current_checkpoint.pt\",\n","                      \"../checkpoint/best_model.pt\"\n","                     )"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"CNN.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}