{"cells":[{"cell_type":"markdown","metadata":{"id":"Sujk-iu9ZInX"},"source":["## MOUNT Google Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19330,"status":"ok","timestamp":1640215616026,"user":{"displayName":"Gradient DESCENT","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17268968097816908368"},"user_tz":-60},"id":"q_M8mC1_OS_J","outputId":"29337e3f-41e0-428c-8097-d7db3be2929d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":673,"status":"ok","timestamp":1640174313735,"user":{"displayName":"Gradient DESCENT","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17268968097816908368"},"user_tz":-60},"id":"OjCxeQgle99a","outputId":"11b5fb17-8ed8-49a5-e090-ee3f4fc5470f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model name:          Intel(R) Xeon(R) CPU @ 2.30GHz\n","Core(s) per socket:  4\n","              total        used        free      shared  buff/cache   available\n","Mem:            51G        935M         47G        1.2M        2.1G         49G\n","Swap:            0B          0B          0B\n","Thread(s) per core:  2\n"]}],"source":["!lscpu |grep 'Model name'\n","!lscpu |grep 'Core(s) per socket:'\n","!free -h\n","!lscpu |grep 'Thread(s) per core'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1639988793779,"user":{"displayName":"Gradient DESCENT","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17268968097816908368"},"user_tz":-60},"id":"7HbCRq5ifH79","outputId":"f0487100-da0c-4fa2-e3b6-3b2655b43238"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mon Dec 20 08:26:33 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"markdown","metadata":{"id":"Fgh7QOsWOITB"},"source":["## IMPORTS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"neDfYKPpOITJ"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim.lr_scheduler import ExponentialLR\n","import numpy as np\n","import random\n","import os, sys, time\n","from PIL import Image\n","import torchvision.transforms as T\n","import matplotlib.image as mpimg\n","import matplotlib.pyplot as plt\n","import scipy.ndimage as sc\n","from PIL import ImageFilter\n","\n","sys.path.append('/content/drive/MyDrive/ml_epfl/ml_road_segmentation/script/')\n","#from helper_functions import *"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1640215626644,"user":{"displayName":"Gradient DESCENT","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17268968097816908368"},"user_tz":-60},"id":"EUAPLcgQOITR","outputId":"f5b751f6-2363-4778-dcf6-4358fdfd1669"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"xdgnn_O4OITV"},"source":["## CONSTANTS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-0QkBAN5OITZ"},"outputs":[],"source":["CHECKPOINT_PATH =\"/content/drive/MyDrive/ml_epfl/ml_road_segmentation/checkpoint/current_checkpoint.pt\"\n","BEST_MODEL_PATH =\"/content/drive/MyDrive/ml_epfl/ml_road_segmentation/checkpoint/best_model.pt\"\n","NBR_EPOCHS = 100\n","BATCH_SIZE = 1\n","LEARNING_RATE = 1e-3\n","WEIGHT_DECAY = 1e-6\n","GAMMA = 1\n","K_FOLD = 4\n","VALIDATION_SET_IDX = 0\n","BATCH_SIZE_VAL = 5\n","SEED = 0\n","DIM_IMG_TRAIN = 400"]},{"cell_type":"markdown","metadata":{"id":"wYk2ZBQ1k-SY"},"source":["## AUXILIARY FUNCTIONS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V6cMVBRK0ZfT"},"outputs":[],"source":["def format_time(seconds):\n","    return time.strftime(\"%H:%M:%S\", time.gmtime(seconds))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oYZCi9--k-0l"},"outputs":[],"source":["def save_ckp(model, state, is_best, checkpoint_path, best_model_path):\n","    \"\"\"\n","    state:            checkpoint we want to save\n","    is_best:          boolean to indicates if it is the best checkpoint\n","    checkpoint_path:  path to save checkpoint\n","    best_model_path:  path to save best model\n","    \"\"\"\n","    torch.save(state, checkpoint_path)\n","    # if it is a best model, save the model's weights\n","    if is_best:\n","        torch.save(model.state_dict(), best_model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T8qqUVVyBdd4"},"outputs":[],"source":["def load_ckp(checkpoint_fpath, model, optimizer):\n","    \"\"\"\n","    checkpoint_path: path to save checkpoint\n","    model:           model that we want to load checkpoint parameters into       \n","    optimizer:       optimizer we defined in previous training\n","    \n","    Return model, optimizer, scheduler, epoch value, f1 score\n","    \"\"\"\n","    checkpoint = torch.load(checkpoint_fpath)\n","    # initialize state_dict from checkpoint to model\n","    model.load_state_dict(checkpoint['state_dict'])\n","    # initialize optimizer from checkpoint to optimizer\n","    optimizer.load_state_dict(checkpoint['optimizer'])\n","    # Get epoch number, f1_max, scheduler\n","    epoch = checkpoint['epoch']\n","    f1_max = checkpoint['f1_max']\n","    scheduler = checkpoint['scheduler']\n","    f1_validation = checkpoint['f1_validation']\n","    acc_validation = checkpoint['acc_validation']\n","    f1_training = checkpoint['scheduler']\n","    acc_training = checkpoint['acc_training']\n","\n","\n","    return model, optimizer, scheduler, epoch, f1_max, f1_validation, acc_validation, f1_training, acc_training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-rAhQhd4ajZS"},"outputs":[],"source":["# FUNCTIONS FOR DATASET AUGMENTATION\n","\n","#Constants\n","DIM_IMG = 400\n","DIM_IMG_CROP=DIM_IMG//2\n","NB_ROT = 20\n","ANGLE_ROTATION = 9\n","    \n","# Old Rotation\n","def rotation_old(imgs):\n","    rot_imgs = [T.functional.rotate(imgs[i], ANGLE_ROTATION*(idx_rot), expand=False)\n","                for idx_rot in range(NB_ROT)\n","                for i in range(len(imgs))\n","                ]\n","    return rot_imgs\n","\n","#Rotation with mirroring\n","def rotation(imgs, angle_rotation, nb_rot):\n","    rot_imgs = [torch.from_numpy(sc.rotate(imgs[i], angle_rotation*(idx_rot+1), axes =(1,2), reshape=False, mode ='mirror'))\n","                for idx_rot in range(nb_rot)\n","                for i in range(len(imgs))\n","               ]\n","    return rot_imgs\n","\n","#Crop and resize\n","def crop(imgs):\n","    cropped_imgs = [T.Resize(size=DIM_IMG)(T.FiveCrop(size=DIM_IMG_CROP)(imgs[i])[tuple_i])\n","                    for tuple_i in range(5)\n","                    for i in range(len(imgs))\n","                   ]\n","    return cropped_imgs\n","\n","#Composing all transformations    \n","def compose_all_functions_for_data(imgs, angle_rotation, nb_rot):\n","    r = imgs + rotation(imgs, angle_rotation, nb_rot)\n","    return r\n","\n","def load_train_dataset():\n","    root_dir = \"/content/drive/MyDrive/ml_epfl/ml_road_segmentation/data/training/\"\n","    image_dir = root_dir + \"images/\"\n","    gt_dir = root_dir + \"groundtruth/\"\n","    files = os.listdir(image_dir)\n","    n = len(files)\n","\n","    to_tensor = T.ToTensor()\n","    imgs = [to_tensor(Image.open(image_dir + files[i])) for i in range(n)]\n","    gt_imgs = [to_tensor(Image.open(gt_dir + files[i])) for i in range(n)]\n","    return (imgs, gt_imgs)"]},{"cell_type":"markdown","metadata":{"id":"Q8je-hU0OITe"},"source":["## UNET MODEL"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZLyDonXtm3a4"},"outputs":[],"source":["def double_conv(nbr_channels_in, nbr_channels_out):\n","    return nn.Sequential(\n","      nn.Conv2d(nbr_channels_in, nbr_channels_out, (3,3), padding=(1, 1)),\n","      nn.BatchNorm2d(nbr_channels_out),\n","      nn.ReLU(),\n","      nn.Conv2d(nbr_channels_out, nbr_channels_out, (3,3), padding=(1, 1)),\n","      nn.ReLU(),\n","      nn.BatchNorm2d(nbr_channels_out),\n",")\n","\n","\n","def one_step_up(x, x_d_i, pre_up_i, up_i):\n","    return up_i(torch.cat((pre_up_i(x), x_d_i), dim=1))\n","\n","\n","class u_net(nn.Module):\n","    def __init__(self):\n","        super(u_net, self).__init__()\n","\n","        self.down_pooling = nn.MaxPool2d(2, 2)\n","\n","        # Convolution Downwards\n","        self.down_1 = double_conv(6, 64) \n","        self.down_2 = double_conv(64, 128)\n","        self.down_3 = double_conv(128, 256)\n","        self.down_4 = double_conv(256, 512)\n","        self.middle =  double_conv(512, 1024)\n","        \n","        # Upconvolution\n","        self.pre_up_1 = nn.ConvTranspose2d(1024, 512, (2, 2), (2, 2))\n","        self.up_1 = double_conv(512 + 512, 512)\n","                \n","        self.pre_up_2 = nn.ConvTranspose2d(512, 256, (2, 2), (2, 2))\n","        self.up_2 = double_conv(256 + 256, 256)\n","          \n","        self.pre_up_3 = nn.ConvTranspose2d(256, 128, (2, 2), (2, 2))\n","        self.up_3 = double_conv(128 + 128, 128)\n","\n","        self.pre_up_4 = nn.ConvTranspose2d(128, 64, (2, 2), (2, 2))\n","        self.up_4 = double_conv(64 + 64, 64)\n","\n","        self.final_convolution = nn.Conv2d(64, 2, (1,1))\n","        \n","\n","    def forward(self, x):\n","        x_d_1 = self.down_1(x)\n","        x_d_2 = self.down_2(self.down_pooling(x_d_1))\n","        x_d_3 = self.down_3(self.down_pooling(x_d_2))\n","        x_d_4 = self.down_4(self.down_pooling(x_d_3))\n","\n","        x = self.middle(self.down_pooling(x_d_4))\n","\n","        x = one_step_up(x, x_d_4, self.pre_up_1, self.up_1)\n","        x = one_step_up(x, x_d_3, self.pre_up_2, self.up_2)\n","        x = one_step_up(x, x_d_2, self.pre_up_3, self.up_3)\n","        x = one_step_up(x, x_d_1, self.pre_up_4, self.up_4)\n","        \n","        return self.final_convolution(x)\n"]},{"cell_type":"markdown","metadata":{"id":"y9vik-NkOITr"},"source":["## DATASET LOADING"]},{"cell_type":"code","source":["def append_filter(filter_to_apply, images):\n","    to_tensor = T.ToTensor() \n","    toPIL = T.ToPILImage()\n","    \n","    concatenated_images = []\n","\n","    for img in images:\n","      filtered_img = toPIL(img).filter(filter_to_apply)\n","      tensored_img = to_tensor(filtered_img)\n","      stacked_img = torch.cat((img, tensored_img), dim=0)\n","      concatenated_images.append(stacked_img)\n","    \n","    return concatenated_images"],"metadata":{"id":"oy_CgAF12GzU"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jac1AXRHm0Nt"},"outputs":[],"source":["class imagesDataset(Dataset): \n","    def __init__(self, K_fold, validation_set_idx, batch_size_val, seed, filter_img, angle_rotation, nb_rot):\n","        X, Y = load_train_dataset()\n","\n","        #tresholding ground_truth values\n","        Y = [(y > 0.5).long() for y in Y]\n","        shape_y = Y[0].shape\n","        \n","        #shuffling\n","        random.seed(seed)\n","        idx_list = list(range(len(X)))\n","        random.shuffle(idx_list)\n","        random.seed()\n","        X = [X[idx] for idx in idx_list]\n","        Y = [Y[idx] for idx in idx_list]\n","        \n","        #K_fold separation\n","        fold_size = len(X) // K_fold\n","        start_validation_idx = validation_set_idx * fold_size\n","        end_validation_idx = start_validation_idx + fold_size\n","        self.X_train = X[slice(0, start_validation_idx)] + X[slice(end_validation_idx, None)]\n","        self.Y_train = Y[slice(0, start_validation_idx)] + Y[slice(end_validation_idx, None)]\n","        self.X_validation = X[slice(start_validation_idx, end_validation_idx)]\n","        self.Y_validation = Y[slice(start_validation_idx, end_validation_idx)]\n","\n","        #data augmentation\n","        self.X_train = compose_all_functions_for_data(self.X_train, angle_rotation, nb_rot)\n","        self.Y_train = compose_all_functions_for_data(self.Y_train, angle_rotation, nb_rot)\n","        self.X_validation = compose_all_functions_for_data(self.X_validation, angle_rotation, nb_rot)\n","        self.Y_validation = compose_all_functions_for_data(self.Y_validation, angle_rotation, nb_rot)\n","        self.n_samples = len(self.X_train)\n","\n","         #apply filter\n","        self.X_train = append_filter(filter_img, self.X_train)\n","        self.X_validation = append_filter(filter_img, self.X_validation)\n","\n","        #2nd shuffling\n","        random.seed(seed)\n","        idx_list = list(range(len(self.X_train)))\n","        random.shuffle(idx_list)\n","        random.seed()\n","        self.X_train = [self.X_train[idx] for idx in idx_list]\n","        self.Y_train = [self.Y_train[idx] for idx in idx_list]\n","        \n","        #casting into tensors\n","        self.X_train = torch.stack(self.X_train)\n","        self.X_validation = torch.stack(self.X_validation)\n","        self.Y_train = torch.reshape(torch.stack(self.Y_train) , (-1, shape_y[1], shape_y[2]))\n","        self.Y_validation = torch.reshape(torch.stack(self.Y_validation) , (-1, shape_y[1], shape_y[2]))\n","\n","        #creating dataloader for validation data\n","        class dataset_validation(Dataset):\n","            def __init__(s,x,y):\n","                s.x = x\n","                s.y = y\n","                s.size = len(s.x)\n","            def __getitem__(s, index):\n","                return s.x[index], s.y[index]\n","            def __len__(s):\n","                return s.size\n","               \n","        self.validation_data_loader = torch.utils.data.DataLoader(\n","            dataset_validation(self.X_validation, self.Y_validation),\n","            batch_size = batch_size_val, shuffle = False)\n","        \n","        \n","    def __getitem__(self, index):\n","        return self.X_train[index], self.Y_train[index]\n","\n","    def __len__(self):\n","        return self.n_samples\n","    \n","    def get_validation_dataloader(self):\n","        return self.validation_data_loader\n","\n"]},{"cell_type":"markdown","metadata":{"id":"wlX6q7XjOIT3"},"source":["## TRAINING"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q7aGRgLs6y34"},"outputs":[],"source":["def compute_scores(model, loader, device):\n","    #computing F1 score on validation data\n","    tp, fp, fn, tn = 0, 0, 0, 0\n","    for (data, target) in loader:\n","        data, target = data.to(device), target.to(device)\n","        with torch.no_grad():\n","            output = model(data)\n","        prediction = torch.argmax(output, dim = 1)\n","        confusions = prediction / target\n","        tp += torch.sum(confusions == 1).item()\n","        fp += torch.sum(confusions == float('inf')).item()\n","        fn += torch.sum(confusions == 0).item()\n","        tn += torch.sum(confusions == float(\"nan\")).item()\n","    f1_score = 2 * tp / (2 * tp + fp + fn)\n","    accuracy = (tp + tn) / (tp + tn + fp+ fn)\n","    return f1_score, accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9pCP7s9fOIT4"},"outputs":[],"source":["def train(n_epochs, data_loader, model, optimizer, scheduler, criterion, device, checkpoint_path, best_model_path, f1_init):\n","    train_loader = data_loader\n","    validation_loader = train_loader.dataset.get_validation_dataloader()\n","    f1_max = f1_init\n","    \n","    save_f1_validation = []\n","    save_acc_validation = []\n","    save_f1_training = []\n","    save_acc_training = []\n","\n","    for epoch in range(n_epochs):\n","        start_time_epoch = time.time()\n","        loss_list = []\n","        \n","        # Train the model for one epoch\n","        model.train()\n","        for (data, target) in train_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            loss = criterion(output, target)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            loss_list.append(loss.item())\n","        loss_epoch = np.mean(loss_list)\n","\n","        model.eval()\n","        #computing scores on validation data\n","        f1_score_val, accuracy_score_val = compute_scores(model, validation_loader, device)\n","        save_f1_validation.append(f1_score_val)\n","        save_acc_validation.append(accuracy_score_val)\n","\n","        #computing scores on training data\n","        f1_score_train, accuracy_score_train = compute_scores(model, train_loader, device)\n","        save_f1_training.append(f1_score_train)\n","        save_acc_training.append(accuracy_score_train)\n","\n","        end_time_epoch = time.time()\n","\n","        # Prepare saving of the model\n","        checkpoint = {\n","            'epoch': epoch,\n","            'f1_max': f1_max,\n","            'state_dict': model.state_dict(),\n","            'optimizer': optimizer.state_dict(),\n","            'scheduler': scheduler,\n","            'f1_validation' : save_f1_validation,\n","            'acc_validation' : save_acc_validation,\n","            'f1_training' : save_f1_training,\n","            'acc_training' : save_acc_training,\n","        }\n","\n","        if f1_score_val > f1_max:\n","            save_ckp(model, checkpoint, True, checkpoint_path, best_model_path)\n","            f1_max = f1_score_val\n","        \n","        save_ckp(model, checkpoint, False, checkpoint_path, best_model_path)\n","\n","        #print(f\"Epoch {epoch} || Loss:{loss_epoch:.6f} || Training F1 {f1_score_train:.6f} || Training Accuracy {accuracy_score_train:.6f} || Validation F1 {f1_score_val:.6f} || Validation Accuracy {accuracy_score_val:.6f} || Max F1 {f1_max:.6f} || LR {scheduler.get_last_lr()[0]:.6f} || Duration {format_time(end_time_epoch-start_time_epoch)}\"+\"\\n\")  \n","        scheduler.step()"]},{"cell_type":"markdown","metadata":{"id":"dcEoThhsD2A9"},"source":["## K-FOLD CROSS VALIDATION (hyper-parameters)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uThwC_hAtOPF","outputId":"c3b8b1ec-83ee-4b18-d180-6dbeb6c5d4fa","executionInfo":{"status":"ok","timestamp":1640164676961,"user_tz":-60,"elapsed":136269,"user":{"displayName":"Gradient DESCENT","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17268968097816908368"}}},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Optimizer SGD - fold 0\n","Optimizer SGD - fold 1\n","Optimizer SGD - fold 2\n","Optimizer SGD - fold 3\n","Optimizer ADAM - fold 0\n","Optimizer ADAM - fold 1\n","Optimizer ADAM - fold 2\n","Optimizer ADAM - fold 3\n","Optimizer ADAM_W - fold 0\n","Optimizer ADAM_W - fold 1\n","Optimizer ADAM_W - fold 2\n","Optimizer ADAM_W - fold 3\n"]}],"source":["\"\"\"CHECKPOINT_K_FOLD_PATH_ROOT =\"/content/drive/MyDrive/ml_epfl/ml_road_segmentation/checkpoint/k_folds_checkpoints/\"\n","BEST_MODEL_K_FOLD_PATH_ROOT =\"/content/drive/MyDrive/ml_epfl/ml_road_segmentation/checkpoint/k_folds_checkpoints/\"\n","\n","# Constants K-Fold\n","K_FOLD = 4\n","LEARNING_RATE_K_FOLD = 1e-3\n","WEIGHT_DECAY_K_FOLD = 1e-6\n","MOMENTUM_SGD_K_FOLD = 0.99\n","GAMMA_K_FOLD = 1\n","SEED_K_FOLD = 0\n","NBR_EPOCHS_K_FOLD = 15\n","BATCH_SIZE_VAL_K_FOLD = 5\n","BATCH_SIZE_K_FOLD = 1\n","FILTER = ImageFilter.FIND_EDGES\n","\n","OPTIMIZERS = [\"SGD_\", \"ADAM_\", \"ADAM_W_\"]\n","\n","for opti_name in OPTIMIZERS:\n","    for idx_validaton_set in range(K_FOLD): \n","        print(f'Optimizer {opti_name[:-1]} - fold {idx_validaton_set}')\n","        \n","        #creating model\n","        model =  u_net().to(device)\n","        \n","        #creating optimizer\n","        optimizer = None\n","        if opti_name == \"SGD_\":\n","            optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE_K_FOLD, weight_decay=WEIGHT_DECAY_K_FOLD, momentum=MOMENTUM_SGD_K_FOLD) \n","        elif opti_name == \"ADAM_\":\n","            optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE_K_FOLD, weight_decay=WEIGHT_DECAY_K_FOLD)\n","        elif opti_name == \"ADAM_W_\":\n","            optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE_K_FOLD, weight_decay=WEIGHT_DECAY_K_FOLD)\n","\n","        scheduler = ExponentialLR(optimizer, GAMMA_K_FOLD)\n","        criterion = nn.CrossEntropyLoss()\n","        dataset = imagesDataset(K_FOLD, idx_validaton_set, BATCH_SIZE_VAL_K_FOLD, SEED_K_FOLD, FILTER)\n","        train_loader = torch.utils.data.DataLoader(dataset, batch_size = BATCH_SIZE_K_FOLD, shuffle = True)\n","        validation_dataloader = dataset.get_validation_dataloader()\n","\n","        # Give correct paths\n","        CHECKPOINT_K_FOLD_PATH = CHECKPOINT_K_FOLD_PATH_ROOT + opti_name + 'fold_' + str(idx_validaton_set) +'_all_data_final.pt' \n","        BEST_MODEL_K_FOLD_PATH = BEST_MODEL_K_FOLD_PATH_ROOT + opti_name + 'fold_' + str(idx_validaton_set) +'_model_final.pt'\n","        train(NBR_EPOCHS_K_FOLD, train_loader, model, optimizer, scheduler, criterion, device, CHECKPOINT_K_FOLD_PATH, BEST_MODEL_K_FOLD_PATH, f1_init = 0)\"\"\""]},{"cell_type":"markdown","source":["## K-FOLD SGD FINAL (for bagging)"],"metadata":{"id":"swWyaKwb0J2Z"}},{"cell_type":"code","source":["K_FOLD_ROOT_PATH_LOADING = \"/content/drive/MyDrive/ml_epfl/ml_road_segmentation/checkpoint/k_folds_checkpoints/\"\n","K_FOLD_ROOT_PATH_WRITTING = \"/content/drive/MyDrive/ml_epfl/ml_road_segmentation/checkpoint/k_folds_bagging/\"\n","\n","# Constants K-Fold\n","K_FOLD = 4\n","LEARNING_RATE_K_FOLD = 1e-3\n","WEIGHT_DECAY_K_FOLD = 1e-6\n","MOMENTUM_SGD_K_FOLD = 0.99\n","GAMMA_K_FOLD = 1\n","SEED_K_FOLD = 0\n","NBR_EPOCHS_K_FOLD = 30\n","BATCH_SIZE_VAL_K_FOLD = 5\n","BATCH_SIZE_K_FOLD = 1\n","FILTER = ImageFilter.FIND_EDGES\n","OPTIMIZERS = [\"SGD_\"]\n","\n","for opti_name in OPTIMIZERS:\n","    for idx_validaton_set in range(K_FOLD): \n","        print(f'Optimizer {opti_name[:-1]} - fold {idx_validaton_set}')\n","        #defining paths\n","        #CHECKPOINT_PATH_LOADING = K_FOLD_ROOT_PATH_LOADING + opti_name + 'fold_' + str(idx_validaton_set) +'_all_data_final.pt'\n","        CHECKPOINT_K_FOLD_PATH = K_FOLD_ROOT_PATH_WRITTING + opti_name + 'fold_' + str(idx_validaton_set) +'_all_data_bagging.pt' \n","        BEST_MODEL_K_FOLD_PATH = K_FOLD_ROOT_PATH_WRITTING + opti_name + 'fold_' + str(idx_validaton_set) +'_model_bagging.pt'\n","\n","        #loading model\n","        checkpoint = torch.load(CHECKPOINT_K_FOLD_PATH)\n","        f1_max = checkpoint['f1_max']\n","        model =  u_net().to(device)\n","        model.load_state_dict(checkpoint[\"state_dict\"])\n","\n","        #defining other parameters\n","        optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE_K_FOLD, weight_decay=WEIGHT_DECAY_K_FOLD, momentum=MOMENTUM_SGD_K_FOLD) \n","        scheduler = ExponentialLR(optimizer, GAMMA_K_FOLD)\n","        criterion = nn.CrossEntropyLoss()\n","\n","        #loading dataset\n","        dataset = imagesDataset(K_FOLD, idx_validaton_set, BATCH_SIZE_VAL_K_FOLD, SEED_K_FOLD, FILTER)\n","        train_loader = torch.utils.data.DataLoader(dataset, batch_size = BATCH_SIZE_K_FOLD, shuffle = True)\n","        validation_dataloader = dataset.get_validation_dataloader()\n","\n","        #resuming training\n","        train(NBR_EPOCHS_K_FOLD, train_loader, model, optimizer, scheduler, criterion, device, CHECKPOINT_K_FOLD_PATH, BEST_MODEL_K_FOLD_PATH, f1_init = f1_max)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CSP9I5gJ0Qgx","outputId":"91d3d7d3-cf33-4002-bad2-931a1f3b6ac9"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Optimizer SGD - fold 0\n"]}]}],"metadata":{"colab":{"background_execution":"on","collapsed_sections":["Sujk-iu9ZInX"],"machine_shape":"hm","name":"u_net_k_fold.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}